{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6HFkgL5v0oq"
      },
      "source": [
        "#Streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install streamlit"
      ],
      "metadata": {
        "id": "753h3rTB0tMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80798bc-a09f-4375-f5bc-90658f5d2de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.2 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 80.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 21.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 36.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 44.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 557 kB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 2.8 MB/s \n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-h0nfP_kOmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "18ce9ec3-4d99-4992-8187-5a966139e64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n",
            "2022-12-13 12:27:57.808 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-effd81b9f164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mdf_talent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'username'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'username'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ユーザーID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ツイート本文'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'プロフィール'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ツイートのURL'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mdf_talent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_talent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ツイート本文'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m   \u001b[0mdf_talent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_talent' is not defined"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import urllib\n",
        "import tqdm\n",
        "import itertools\n",
        "import requests\n",
        "from datetime import date\n",
        "from dateutil import relativedelta\n",
        "import collections\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from datetime import timedelta\n",
        "import plotly.graph_objects as go\n",
        "import gspread\n",
        "import gspread_dataframe\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import networkx as nx\n",
        "import warnings\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def request_search(bearer_token, params, max_count):\n",
        "\n",
        "    tweets = []\n",
        "    expanded = {\n",
        "        \"tweets\": [],\n",
        "        \"users\": []\n",
        "    }\n",
        "\n",
        "    next_token = None\n",
        "\n",
        "    while True:\n",
        "        if next_token is not None:\n",
        "            params[\"next_token\"] = next_token\n",
        "\n",
        "        url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "        encoded_params = urllib.parse.urlencode(params)\n",
        "        headers = {\"Authorization\": f\"Bearer AAAAAAAAAAAAAAAAAAAAAJ5bZwEAAAAAdlSGg9zHc8pH2IKr5HgBllUg3SA%3D3ZpLpfDZHf4Sd01v4np7rJcr3DyEXBfNTWBfpOGST30OtqGGdG\"}\n",
        "        res = requests.request(\n",
        "            \"GET\", url, params=encoded_params, headers=headers)\n",
        "\n",
        "        if res.status_code == 429:\n",
        "            rate_limit_reset = int(res.headers[\"x-rate-limit-reset\"])\n",
        "            now = time.mktime(datetime.datetime.now().timetuple())\n",
        "            wait_sec = int(rate_limit_reset - now)\n",
        "            desc = f\"Waiting for {wait_sec} seconds\"\n",
        "            for _ in tqdm.trange(wait_sec, desc=desc):\n",
        "                time.sleep(1)\n",
        "\n",
        "        elif res.status_code != 200:\n",
        "            raise Exception(res.status_code, res.text)\n",
        "\n",
        "        else:\n",
        "            res_json = res.json()\n",
        "\n",
        "            if res_json[\"meta\"][\"result_count\"] == 0:\n",
        "                break\n",
        "\n",
        "            tweets += res_json[\"data\"]\n",
        "            print(f\"{len(tweets)}件のツイートを取得しました。\")\n",
        "\n",
        "            if res_json.get(\"includes\"):\n",
        "                includes = res_json[\"includes\"]\n",
        "                for k, v in expanded.items():\n",
        "                    if includes.get(k):\n",
        "                        \n",
        "                        expanded[k] += includes[k]\n",
        "\n",
        "            next_token = res_json.get(\"meta\").get(\"next_token\")\n",
        "            if next_token is None or len(tweets) >= max_count:\n",
        "                break\n",
        "\n",
        "    return tweets[:max_count], expanded\n",
        "\n",
        "\n",
        "def export_json(fpath, data):\n",
        "    with open(fpath, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "\n",
        "\n",
        "def search_tweet(max_count,keyword,value):\n",
        "\n",
        "  dt_now_jst_aware = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  print((dt_now_jst_aware - relativedelta.relativedelta(hours=value)).isoformat())\n",
        "  print((dt_now_jst_aware - relativedelta.relativedelta(minutes=1)).isoformat())\n",
        "\n",
        "\n",
        "  bearer_token = \"AAAAAAAAAAAAAAAAAAAAAJ5bZwEAAAAAdlSGg9zHc8pH2IKr5HgBllUg3SA%3D3ZpLpfDZHf4Sd01v4np7rJcr3DyEXBfNTWBfpOGST30OtqGGdG\"\n",
        "  max_count = max_count\n",
        "\n",
        "  params = {\n",
        "      \"query\":keyword + str('-RT'),\n",
        "      \"start_time\": (dt_now_jst_aware - relativedelta.relativedelta(hours=value)).isoformat(),\n",
        "      \"end_time\": (dt_now_jst_aware - relativedelta.relativedelta(minutes=1)).isoformat(),\n",
        "      \"expansions\": \"author_id,entities.mentions.username,geo.place_id,in_reply_to_user_id,referenced_tweets.id,referenced_tweets.id.author_id\",\n",
        "      \"max_results\": \"100\",\n",
        "      \"media.fields\": \"duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics\",\n",
        "      \"place.fields\": \"contained_within,country,country_code,full_name,geo,id,name,place_type\",\n",
        "      \"poll.fields\": \"duration_minutes,end_datetime,id,options,voting_status\",\n",
        "      \"tweet.fields\": \"attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld\",\n",
        "      \"user.fields\": \"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld\"\n",
        "  }\n",
        "\n",
        "\n",
        "  tweets, expanded = request_search(bearer_token, params, max_count)\n",
        "\n",
        "\n",
        "  df_tweet = pd.DataFrame()\n",
        "  df_tweet_ex = pd.DataFrame()\n",
        "  for i in range(0,len(tweets)):\n",
        "      try:\n",
        "          #df_tweet.loc[i,'created_at'] = pd.to_datetime(tweets[i]['created_at']) + datetime.timedelta(hours=9)\n",
        "          df_tweet.loc[i,'author_id'] = tweets[i]['author_id']\n",
        "          df_tweet.loc[i,'text'] = tweets[i]['text']\n",
        "          #df_tweet.loc[i,'tweet_id'] = tweets[i]['id']\n",
        "          df_tweet.loc[i,'like_count'] = tweets[i]['public_metrics']['like_count']\n",
        "          df_tweet.loc[i,'retweet_count'] = tweets[i]['public_metrics']['retweet_count']\n",
        "          #df_tweet.loc[i,'reply_count'] = tweets[i]['public_metrics']['reply_count']\n",
        "\n",
        "          #df_tweet_ex.loc[i,'regist_date'] = pd.to_datetime(expanded['users'][i]['created_at']) + datetime.timedelta(hours=9)\n",
        "          df_tweet_ex.loc[i,'name'] = expanded['users'][i]['name']\n",
        "          df_tweet_ex.loc[i,'username'] = expanded['users'][i]['username']\n",
        "          df_tweet_ex.loc[i,'description'] = expanded['users'][i]['description']\n",
        "          #df_tweet_ex.loc[i,'following_count'] = expanded['users'][i]['public_metrics']['following_count']\n",
        "          #df_tweet_ex.loc[i,'followers_count'] = expanded['users'][i]['public_metrics']['followers_count']\n",
        "          #df_tweet_ex.loc[i,'listed_count'] = expanded['users'][i]['public_metrics']['listed_count']\n",
        "          #df_tweet_ex.loc[i,'tweet_count'] = expanded['users'][i]['public_metrics']['tweet_count']\n",
        "          #df_tweet_ex.loc[i,'prof_link'] = expanded['users'][i]['url']\n",
        "          #df_tweet_ex.loc[i,'pinned_tweet_id'] = expanded['users'][i]['pinned_tweet_id']\n",
        "          df_tweet_ex.loc[i,'author_id'] = expanded['users'][i]['id']\n",
        "\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "\n",
        "  df_tweet = df_tweet.merge(df_tweet_ex,on='author_id',how='inner')\n",
        "  df_tweet['url'] = df_tweet['username'].apply(lambda x: 'https://twitter.com/' + str(x))\n",
        "  df_tweet = df_tweet[['name','username','text','description','retweet_count','like_count','url']]\n",
        "  return df_tweet\n",
        "\n",
        "def make_clickable(val): \n",
        "  return '<a href=\"{}\">{}</a>'.format(val,val)\n",
        "\n",
        "\n",
        "#---------- Web apps ----------#\n",
        "import streamlit as st\n",
        "import base64\n",
        "\n",
        "\n",
        "pagelist = [\"TPA\",\"Analytics\"]\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "selector=st.sidebar.selectbox( \"Mode\",pagelist)\n",
        "if selector==\"TPA\":\n",
        "  st.title(\"Talentum：Talent Pool Automation\")\n",
        "  cnt=st.number_input('探索ツイート数の設定：0~50000',0,50000,0,step=1)\n",
        "  keyword = st.text_input('人材探索キーワードの設定 半角で入力ください')\n",
        "  st.text_area('分析メモ')\n",
        "\n",
        "\n",
        "  talent_search = st.button(\"Search Talent\")\n",
        "  if talent_search :\n",
        "    df_tweet = search_tweet(cnt,keyword,24*6.9)\n",
        "    df_talent = df_tweet[['username','text','description','url']].rename(columns={'username':'ユーザーID','text':'ツイート本文','description':'プロフィール','url':'ツイートのURL'})\n",
        "    df_talent = df_talent.groupby('ツイート本文',as_index=False).head(1)\n",
        "  df_talent\n",
        "\n",
        "\n",
        "#  description = st.text_input('プロフに含まれるキーワードの設定 （正規表現）')\n",
        "#  profile_search = st.button(\"check profile\")\n",
        "#  if profile_search :\n",
        "#    df_display = df_talent[df_talent['description'].str.contains('description')]\n",
        "#  df_display\n",
        "\n",
        "\n",
        "  csv = df_talent.to_csv(index=False)\n",
        "  b64 = base64.b64encode(csv.encode()).decode()\n",
        "  href = f'<a href=\"data:application/octet-stream;base64,{b64}\" download=\"result_utf-8.csv\">Download Link</a>'\n",
        "  st.markdown(f\"人材探索データのダウンロード（csv）:  {href}\", unsafe_allow_html=True)\n",
        "\n",
        "elif st.button('Analytics'):\n",
        "  st.title(\"Coming soon\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.view(\"/content\")\n",
        "files.view(\"app.py\")"
      ],
      "metadata": {
        "id": "ZRhMaR39jGul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & sleep 3 && npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "FBshsluD06PV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6HFkgL5v0oq"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}